---
title: "Data Cleaning"
output: html_notebook
editor_options: 
  chunk_output_type: console
---
Setting path
NOTE: In order to run the script smoothly we recommend to have saved the folder
containing all the data sets in a separate folder called "Data-OW"
```{r Path Setting}
path = "../Data-OW/"
```

Importing libraries
```{r Importing Libraries and parameters setting}
pacman::p_load(readxl,lubridate,dplyr,timechange,stringr, 
               ggplot2, ggrepel, tidyverse, ggcharts)

# Removing scientific notation

options(scipen=999)
```

___________________________________________________
# DimProduct dataset

Setting the working directory and importing the datasets
```{r Laoding Product.df}
head(product.df <- read.csv(paste0(path,"Hackathon_DimProduct_SAN_vShared.csv"), 
                       header = TRUE), 5)
str(product.df)
```

Cleaning ProductKey Column
Note on RegEx: (i?) is used to render the match case insensitive
```{r Cleaning ProductKey}
length(product.df$ProductKey <- gsub("(i?)key_", "", product.df$ProductKey))

# OK
```

Cleaning Product Sub-Category column. Indeed, lv2. has some categories that needs to be transformed from lower case to upper case before the substitution.
Note on RegEx used: - (\\w*) = takes every word up to infinite times
                    - (\\s)  = considers the first space present in the string
                    - Combination of the two = Take all the words before a space (included)
```{r Cleaning Product Category}
product.df$ProductCategory_Lvl1 <- toupper(gsub("(\\w*\\s)", "", 
                                        product.df$ProductCategory_Lvl1))

product.df$ProductCategory_Lvl2 <- toupper(gsub("(\\w*\\s)", "", 
                                        product.df$ProductCategory_Lvl2))

# toUpper has been used as remedy to the difference in case present
# in the vectors
```

Transforming categories into factors
```{r Factorization}
product.df$ProductCategory_Lvl1 <- as.factor(product.df$ProductCategory_Lvl1)
product.df$ProductCategory_Lvl2 <- as.factor(product.df$ProductCategory_Lvl2)
```

____________________
Quick exploration of categories
```{r Exploration}
table(product.df$ProductCategory_Lvl1) # Only Category A
```

At lv.1 only A category is present in the dataset

```{r Exploration}
table(product.df$ProductCategory_Lvl2)
```
Product suppliers
```{r Exploration}
length(unique(product.df$SupplierKey))
```
There are 17 Product suppliers

```{r}
length(unique(product.df$BrandKey))
```
There are 24 Brands
________________________________________________________________________________
# CPI dataset

```{r Loaging CPI.df} 
head(cpi.df <- read_xlsx(paste0(path, "Consumer Price Index_vShared.xlsx")))
```
Understanding type of variables
```{r Overview}
str(cpi.df)
```

Setting up the date format for CPI
```{r Date format induction}
cpi.df$Date_daily <- as.character(cpi.df$Date_daily)
cpi.df$Date_daily <- as.POSIXct(cpi.df$Date_daily, 
                                format = "%Y-%m-%d",
                                tz = time_at_tz(
                                  Sys.timezone(location = TRUE)))
```


```{r Overview}
summary(cpi.df)
```

```{r Checking for duplicates}
any(duplicated(cpi.df))
```

No duplicates in the dataset

## Plotting average monthly CPI
```{r}
plot(unique(cpi.df$CPI_monthly),
     type = "l", xlab = "Month", ylab = "Average monthly CPI")
```


___________________________________________________
# Promotion dataset

```{r Laoding Promotion.df}
head(promotion.df <- read.table(paste0(path,"Hackathon_DimPromotion_SAN_vShared.csv"), 
                                header = TRUE,
                                sep = ","))
str(promotion.df)
```

Transforming PromotionKey into character (might be transformed into factor later)
```{r Characterization}
promotion.df$PromotionKey <- as.character(promotion.df$PromotionKey)
```

Transforming Promotion Dates into POSIXct formats
```{r Dates as.Date}
promotion.df$PromotionStartDate <- as.POSIXct(promotion.df$PromotionStartDate,
                                              format = "%m/%d/%Y",
                                              tz = time_at_tz(
                                                Sys.timezone(location = TRUE)))

promotion.df$PromotionEndDate <- as.POSIXct(promotion.df$PromotionEndDate,
                                            format = "%m/%d/%Y",
                                            tz = time_at_tz(
                                              Sys.timezone(location = TRUE)))
```

Transforming promotion mechanics into factor
```{r Factorization}
table(promotion.df$PromoMechanic <- as.factor(promotion.df$PromoMechanic))
```
There are 15 promotion types + 1 unknown

```{r Overview}
summary(promotion.df)
```
No missing values

```{r}
promotion.df <- promotion.df %>% 
  mutate(duration = round(difftime(PromotionEndDate,
                                   PromotionStartDate,
                                   units = "days"),
                          digits = 0))

```

```{r}
plot(promo.avg.duration <- promotion.df %>% 
  group_by(PromoMechanic) %>% 
  summarise(avg.duration = mean(duration)), type = "b")
```

```{r Unknown promotions}
view(unknown.promotions <- promotion.df[promotion.df$PromoMechanic == "Unknown",])
```

Some unknown promotions are set without ending date, as a default is equal to 2049-12-31

```{r Duplicates in promotion}
any(duplicated(promotion.df))
```
No duplicates

OK

____________________________________________-
# Store Dataset

```{r Loading Store.df}
head(store.df <- read.table(paste0(path, 
                                   "Hackathon_DimStore_SAN_vShared.csv"), 
                           header = TRUE,
                           sep = ","))
```

```{r Overview}
str(store.df)
```

Adjusting StoreType and transforming it into factor
Note on RegEx: (\S+\s\S+) serves two take the first two words in the string, where \\S+ is the negation of \s, thus taking all the words excluding the space and \\s considers exactly the spaces. The combination takes thus exactly the first two words before a second space 

```{r Cleaning miswritten StoreType}
store.df$StoreType <- gsub("(\\S+\\s\\S+)", "", store.df$StoreType)
store.df$StoreType <- as.factor(store.df$StoreType)
```

Adjusting Region_lvl 1 and 2 and transforming into factors
Note on RegEx: - [A-Z](?!.*[A-Z].* takes just the last capital letter
               - \\d+ is takes just the first group of number
```{r Cleaning miswritten Region_Lvl}
store.df$Region_Lvl1 <- str_extract(store.df$Region_Lvl1, "[A-Z](?!.*[A-Z].*)")
store.df$Region_Lvl2 <- str_extract(store.df$Region_Lvl2, "\\d+")

store.df$Region_Lvl1 <- as.factor(store.df$Region_Lvl1)
store.df$Region_Lvl2 <- as.factor(store.df$Region_Lvl2)
```

Final check
```{r Exploration}
table(store.df$Region_Lvl1)
as.data.frame(sort(table(store.df$Region_Lvl2), decreasing = T))
```

```{r Check store key duplicates}
# Check for duplicates
any(duplicated(store.df))
store.df <- distinct(store.df)
```


Transforming StoreKey and DistributionChannel into factors
```{r Factorization of StoreKey and DistributionChannel}
store.df$StoreKey <- as.factor(store.df$StoreKey)
store.df$DistributionChannel <- as.factor(store.df$DistributionChannel)
```

OK
_____________________________________
# Trasaction Dataset

```{r Loading Transaction.df}
head(transaction.df <- read.table(paste0(path,
                       "Hackathon_FactSalesTransactionDATES_vShared.csv"),
                                  header = TRUE,
                                  sep = ","))
```

```{r Overview}
str(transaction.df)
```
During the analysis we noticed a mismatch between transaction.df, store.df and product.df due to a mismatch in the expression of the keys, so we make a few adjustments before proceeding. 
Note on RegEx: \\s* serves to match one or more blank spaces before and after the spcified string
                _?  serves to look for possible underscore before the string and after the space
                [kK][eE][yY] is the word to look for in every possible combination of upper and lower                 case
```{r StoreKey and ProductKey adjustment}
head(transaction.df$StoreKey <- gsub("\\s*_?[kK][eE][yY]\\s*", "", transaction.df$StoreKey), 10)
head(transaction.df$ProductKey <- gsub("\\s*_?[kK][eE][yY]\\s*", "", transaction.df$ProductKey), 10)
```

```{r Check for duplicates}
# any(duplicated(transaction.df)) too long to compute (TRUE)
```


```{r Checking if there is a match between keys}
length(unique(store.df$StoreKey))
length(unique(transaction.df$StoreKey))

length(unique(product.df$ProductKey))
length(unique(transaction.df$ProductKey))
```

Not all StoreKey in the transactions dataset are present (724 against 299).
There is one ProductKey without a match (299 against 298)

```{r Check ProductKey}
(missing.productkey <- transaction.df[!(transaction.df$ProductKey
                                       %in% product.df$ProductKey),])
```

There are 23978 registered transactions without information that need to be removed

```{r Removing missing values}
transaction.df <- transaction.df[transaction.df$ProductKey != "",]
remove(missing.productkey)
```


Trasforming TransactionDate into POSIXct format (it takes a while)
```{r Dates as.Date}
head(transaction.df$TransactionDate <- as.POSIXct(transaction.df$TransactionDate,
                                                  format = "%Y-%m-%d",
                                                  tz = time_at_tz(
                                                    Sys.timezone(location = TRUE))))

```

Transforming DayOfWeek, WeekendFlag, StoreKey and ProductKey into factors
```{r Factorization}
transaction.df$DayOfWeek <- factor(transaction.df$DayOfWeek,
                                   levels=c('Monday', 'Tuesday', 'Wednesday',
                                            'Thursday', 'Friday', 'Saturday',
                                            'Sunday'))
transaction.df$WeekendFlag <- as.factor(transaction.df$WeekendFlag)
transaction.df$StoreKey <- as.factor(transaction.df$StoreKey)
transaction.df$ProductKey <- as.factor(transaction.df$ProductKey)
```

```{r Overview}
summary(transaction.df)
```
```{r 2012 transactions}
unique(year(transaction.df$TransactionDate))

transactions.2012 <- transaction.df %>% 
  filter(year(TransactionDate) == 2012)

# Removing 2012 transactions, possible mistakes but not addressable to 2012
transaction.df <- transaction.df %>% 
  filter(year(TransactionDate) != 2012)
```


There are still 72125 missing values in ActualSales
```{r Testing 72125 missing values}
test1 <- transaction.df %>% 
  filter(is.na(transaction.df$ActualSales))

summary(test1)
```

By comparing the two summaries we can see that the full dataset entails SalesDiscount both negative and positive while the subset of transactions where the "ActualSales" are missing has only negative discounts.
-> We can derive: ActualSales = RetailFullPrice + (-SalesDiscount)
since SalesDiscount for missing ActualSales has only negative values

We will later explore positive values of sales discount

Deriving missing ActualSales
```{r NAs imputation}
head(transaction.df$ActualSales[is.na(transaction.df$ActualSales)] <- transaction.df$RetailFullPrice[is.na(transaction.df$ActualSales)] 
+ transaction.df$SalesDiscount[is.na(transaction.df$ActualSales)])
```

Checking again the summary
```{r Overivew}
summary(transaction.df)
```
No more missing values 

```{r Removing Test}
remove(test1)
```

OK
________________________________________________________________________________
# Trasaction Promotion Data set
```{r Laoding Transaction.Promotion.df}
head(transaction.promotion.df <-read.table(paste0(path,
                                             "Hackathon_FactSalesTransactionPromotion_vShared.csv"),
                                       header = TRUE,
                                       sep = ","))
```

Transforming TransactionDate into POSIXct format
```{r Dates as.Date}
transaction.promotion.df$TransactionDate <-
  as.POSIXct(transaction.promotion.df$TransactionDate,
                                                       format = "%Y-%m-%d",
                                                       tz = time_at_tz(
                                                         Sys.timezone(location =
                                                                        TRUE)))

```

Explanation on RegEx: See above in section "StoreKey and ProductKey adjustment for transaction.df"
```{r Cleaning StoreKey}
#Checking keys
unique(transaction.promotion.df$StoreKey)
transaction.promotion.df$StoreKey <- gsub("\\s*_?[kK][eE][yY]\\s*", "", transaction.promotion.df$StoreKey)
```

Transforming StoreKey, ProductKey and Promotion Key into factors
```{r Factorization}
transaction.promotion.df$StoreKey <- as.factor(transaction.promotion.df$StoreKey)
transaction.promotion.df$ProductKey <- as.factor(transaction.promotion.df$ProductKey)
transaction.promotion.df$PromotionKey <-
  as.factor(transaction.promotion.df$PromotionKey)
```

```{r Overview}
summary(transaction.promotion.df)
```

Such function will be used lately for splitting in different years the data set. This
will be useful for the 3rd task, which regards creating a machine learning algorithm,
for training and testing purposes.
```{r Creating splitting function specifically for transaction.df}

splitting_years <- function(transaction.df,start,end){
        return(transaction.df[between(transaction.df$TransactionDate, 
               as.POSIXct(start,
                          format = "%Y-%m-%d",
                          tz = time_at_tz(
                            Sys.timezone(location = TRUE))), 
               as.POSIXct(end,
                          format = "%Y-%m-%d",
                          tz = time_at_tz(
                            Sys.timezone(location = TRUE)))),])
  }
```

_____________________________________
# Holiday

```{r Laoding Holiday.df}
head(holiday.df <- read.table(paste0(path,"Hackathon_HolidaysMY_vShared.csv"), 
                                       header = TRUE,
                                       sep = ","))
```
# Merging data sets
Note: Since the transactions go from 2020.01.01 to 2022.12.31, it has been decided to remove the dates that were present concerning dates not in the 
scrutinized timespan

```{r Date as.Date}
cpi.df<- cpi.df[between(cpi.df$Date_daily, as.POSIXct("2020-01-01"), as.POSIXct("2022-12-31")),]

promotion.df <- promotion.df[between(promotion.df$PromotionStartDate, as.POSIXct("2020-01-01"), as.POSIXct("2022-12-31")),]

```

# Creating Dataset for next tasks and the Interactive Dashboard
```{r Merged Data set}
# Trial 
a <- merge(transaction.df, store.df)
b <- merge(a, product.df)
c <- left_join(b, transaction.promotion.df, by =  c("TransactionDate", "StoreKey", "ProductKey"))
transaction.df <- left_join(c, promotion.df, by = "PromotionKey") 
transaction.df <- transaction.df %>% 
  filter(TransactionDate >= as.POSIXct("2020-01-01",format = "%Y-%m-%d", tz = ""))

save(transaction.df, file = paste0(path,"MergedData.RData"))
```

## Exploration of missing values

```{r Summary}
summary(transaction.df)
```

```{r Interactive Dashboard Data set}

sales_volumes <- transaction.df %>% 
  select(TransactionDate, ActualSales, DistributionChannel, SalesDiscount, ProductCategory_Lvl2, StoreKey, UnitVolume, ProductKey, PromoMechanic, Region_Lvl1, Region_Lvl2, StoreType) %>% 
  filter(TransactionDate >= as.POSIXct("2020-01-01",format = "%Y-%m-%d", tz = "")) %>% 
  na.omit()

save(sales_volumes, file = paste0(path,"DBData.RData"))
```
