---
title: "Forecasting Baseline"
output: html_document
date: "2023-03-04"
---
Setting path
NOTE: In order to run the script smoothly we recommend to have saved the folder
containing all the data sets in a separate folder called "Data-OW"

```{r Path Setting}
path = "../Data-OW/"
```

Importing libraries
```{r Importing Libraries and parameters setting}
pacman::p_load(readxl,lubridate,dplyr,timechange,stringr, 
               ggplot2, ggrepel, tidyverse, ggcharts, car, forecast, scales, tidyquant, 
               gridExtra, tibbletime, itsmr, here, fpp2, tseries)

# Removing scientific notation

options(scipen=999)
```

```{r Loading the necessary data}

load(paste0(path, "MergedData.RData"))
cpi.df <- read_xlsx(paste0(path, "Consumer Price Index_vShared.xlsx"))
holiday.df <- read.table(paste0(path,"Hackathon_HolidaysMY_vShared.csv"), 
                                       header = TRUE,
                                       sep = ",")

```

```{r Brief Data sets preparation}

cpi.df$Date_daily <- as.character(cpi.df$Date_daily)
cpi.df$Date_daily <- as.POSIXct(cpi.df$Date_daily, 
                                format = "%Y-%m-%d",
                                tz = time_at_tz(Sys.timezone(location = TRUE)))

cpi.df<- cpi.df[between(cpi.df$Date_daily, as.POSIXct("2020-01-01"), as.POSIXct("2022-12-31")),]
```
Note one thing from this plot: 4 Products are displayed where two, namely 49329 and 49333 have been bought
every single day throughout the 3 years. On the other hand 49340, has been bought 1039 (57 days without have been purchased) and 49341 "just" 896 times. In these cases we will have to force such dates with "0" volumes sold. 
```{r Creating Prediction Dataset}
Date <-as.data.frame(cpi.df[,3:4]) # Required to be sure to have all the dates in the following data set
colnames(Date) <- c("Date", "CPI_daily")
Date$Weekday <- factor(weekdays(Date$Date), levels = c("Monday", "Tuesday", "Wednesday",
                                                       "Thursday", "Friday", "Saturday", "Sunday"))
Date$WeekendFlag[Date$Weekday == "Saturday" | Date$Weekday == "Sunday"] <- "TRUE"
Date$WeekendFlag[which(is.na(Date$WeekendFlag))] <- "FALSE"
Date$WeekendFlag <- factor(Date$WeekendFlag, levels = c("TRUE", "FALSE"))
```

Note on how the data set has been created: We decided to see whether a day was "in promotion" or not
considering the the sum of discounts and the sum of total sales for that specific day. In doing so we will 
obtain 1096 days in whihc some have to be considered as promotion and will have to be forecasted and other that will be used as baseline

```{r Creating the dataset for the model}
# Filtering by ProductKey
# Note: The analysis will be performed fro productKey = 49340. For the rest a function will be used
product.code.filter <- c("49340")

sales <- transaction.df %>% 
  select(ProductKey, TransactionDate, UnitVolume, ActualSales, SalesDiscount,
         RetailFullPrice, DistributionChannel) %>% 
  filter(DistributionChannel == "Physical" &
           ProductKey %in% product.code.filter) %>% 
  group_by(ProductKey, TransactionDate) %>% 
  summarise(SumDiscounts = sum(SalesDiscount),
            TotSales = sum(RetailFullPrice),
            TotVolumes = sum(UnitVolume)) %>% 
  mutate(PromoFlag = case_when((abs(SumDiscounts)/TotSales) > 0.05 ~ 1,
                               TRUE ~ 0),
         Date = TransactionDate) %>% 
  ungroup()

df <- left_join(Date, sales, by = c("Date" = "TransactionDate"))
df$ProductKey <- droplevels(df$ProductKey)
df$ProductKey[which(is.na(df$ProductKey))] <- product.code.filter
df$SumDiscounts[which(is.na(df$SumDiscounts))] <- 0
df$TotSales[which(is.na(df$SumFullPrices))] <- 0
df$TotVolumes[which(is.na(df$TotVolumes))] <- 0
df$Trend <- 1:length(df$TotVolumes)
df$PromoFlag <- as.factor(df$PromoFlag)

# Check for missing values
summary(df) # No missing values
table(df$PromoFlag)
```


```{r Adding Exogenous factors}
load(paste0(path, "holidays.df.RData"))

df <- left_join(df, holidays.df, by = "Date")
df <- df %>% 
  mutate(Festivity = case_when(is.na(Festivity) ~ 0,
                   TRUE ~ 1))
df$Festivity <- as.factor(df$Festivity)

# Checking
table(df$Festivity)
```

```{r Completed Data set for Baseline Predction and related Plot}
View(df)
```

```{r Plot}
ggplot(data = df,
       aes(x = Date, y = TotVolumes, group = ProductKey,
                                colour = factor(ProductKey))) +
  geom_line(linetype = "solid") +
  #geom_point() +
  geom_hline(yintercept = mean(df$TotVolumes)) +
  ylab("TotVolumes") +
  xlab("Date") +
  theme(legend.title = element_blank())
```
It looks like our time series is highly autocorrelated. Is it stationary though? 
According to what the ACF displays, it seems the process is non-stationary. We will deal with it with differentiation hoping it will resolve the problem

```{r ACF}
ggAcf(df$TotVolumes, lag.max = 104)
ggPacf(df$TotVolumes)
```
```{r Differencing}
df$TotVolumes %>% diff(lag=7) %>% ggtsdisplay() # Looks like differencing works but a clear pattern seems to be still present. The PACF and ACF suggest an MA model on differenced data with Seasonal component. 
```

```{r SARIMAX}
baseline_Auto_SARIMAX = auto.arima(as.vector(df[,"TotVolumes"]), # specify main trend
                              xreg = data.matrix(df[,c("CPI_daily", "WeekendFlag", "Festivity", "Trend", "PromoFlag")]), # specify exogenous variables here
                              trace = TRUE,
                              seasonal = TRUE, # allow a SARIMAX model
                              stepwise = TRUE,
                              approximation = FALSE) 

```
```{r Testing}
checkresiduals(baseline_SARIMAX)
test(resid(baseline_SARIMAX))
autoplot(baseline_SARIMAX)

summary(baseline_SARIMAX)
```

```{r Predicting Baseline}
# Creating data set where no promotions are present an trying to predict the missing ones
dataset <- df[,c("CPI_daily", "WeekendFlag", "Festivity", "Trend", "PromoFlag")]
dataset$PromoFlag <- rep(0, length(dataset$PromoFlag))
dataset$PromoFlag <- as.factor(dataset$PromoFlag)
summary(dataset)
str(dataset)

## produce forecasts
myforecasts <- forecast::forecast(baseline_Sarimax, xreg=data.matrix(dataset))
baseline <- as.data.frame(cbind(myforecasts$fitted, as.character(Date$Date)))
colnames(baseline) <- c("Forecasts", "Date")
baseline$Date <- as.POSIXct(baseline$Date, format = "%Y-%m-%d",
                                tz = time_at_tz(Sys.timezone(location = TRUE)))
baseline$Forecasts <- as.numeric(baseline$Forecasts)
baseline$TrueValues <- df$TotVolumes

## plot the forecasts

ggplot(data = baseline,
       aes(x = Date, y = Forecasts)) +
  geom_line(linetype = "solid", color = "blue") +
  geom_line(aes(x = Date, y = TrueValues), color = "red", alpha = 0.7) +
  #geom_point() +
  geom_hline(yintercept = mean(baseline$Forecasts)) +
  ylab("TotVolumes") +
  xlab("Date") +
  theme(legend.title = element_blank())
```

```{r Linear Model ? }
dataset$TotVolumes <- df$TotVolumes
lm  <- lm(data = df, log(TotVolumes) ~ CPI_daily + Trend + I(Trend^2) + Festivity + PromoFlag)

summary(lm)
head(exp(lm$fitted.values))

baseline <- as.data.frame(cbind(exp(lm$fitted.values), as.character(Date$Date)))
colnames(baseline) <- c("Forecasts", "Date")
baseline$Date <- as.POSIXct(baseline$Date, format = "%Y-%m-%d",
                                tz = time_at_tz(Sys.timezone(location = TRUE)))
baseline$Forecasts <- as.numeric(baseline$Forecasts)
baseline$TrueValues <- df$TotVolumes

## plot the forecasts

ggplot(data = baseline,
       aes(x = Date, y = Forecasts)) +
  geom_line(linetype = "solid", color = "blue") +
  geom_line(aes(x = Date, y = TrueValues), color = "red", alpha = 0.7) +
  #geom_point() +
  geom_hline(yintercept = mean(baseline$Forecasts)) +
  ylab("TotVolumes") +
  xlab("Date") +
  theme(legend.title = element_blank())
```

```{r Uplift}
# Looking for the dates in which promotions have been activated
(dates_elasticity <- df$Date[which(df$PromoFlag == 1)]) # Succession of days...interesting
Actual <- df %>% filter(Date %in% dates_elasticity) %>%  select(TotVolumes) 
Base <- baseline %>% filter(Date %in% dates_elasticity) %>%  select(Forecasts) 
Uplift <- Actual - Base
Discount <- df %>% filter(Date %in% dates_elasticity) %>% select(SumDiscounts)
Elasticity <- -Uplift/Discount

```

```{r Elasticity Function}
elasticity <- function(Product) {

sales <- transaction.df %>% 
  select(ProductKey, TransactionDate, UnitVolume, ActualSales, SalesDiscount,
         RetailFullPrice, DistributionChannel) %>% 
  filter(DistributionChannel == "Physical" &
           ProductKey %in% Product) %>% 
  group_by(ProductKey, TransactionDate) %>% 
  summarise(SumDiscounts = sum(SalesDiscount),
            TotSales = sum(RetailFullPrice),
            TotVolumes = sum(UnitVolume)) %>% 
  mutate(PromoFlag = case_when((abs(SumDiscounts)/TotSales) > 0.05 ~ 1,
                               TRUE ~ 0),
         Date = TransactionDate) %>% 
  ungroup()

df <- left_join(Date, sales, by = c("Date" = "TransactionDate"))
df$ProductKey <- droplevels(df$ProductKey)
df$ProductKey[which(is.na(df$ProductKey))] <- product.code.filter
df$SumDiscounts[which(is.na(df$SumDiscounts))] <- 0
df$TotSales[which(is.na(df$SumFullPrices))] <- 0
df$TotVolumes[which(is.na(df$TotVolumes))] <- 0
df$Trend <- 1:length(df$TotVolumes)

df <- left_join(df, holidays.df, by = "Date")
df <- df %>% 
  mutate(Festivity = case_when(is.na(Festivity) ~ 0,
                   TRUE ~ 1))
df$Festivity <- as.factor(df$Festivity)
baseline_Sarimax<- Arima(as.vector(df[,"TotVolumes"]), 
                         order=c(2,1,2), 
                         seasonal=c(1,0,0),
                         xreg = data.matrix(df[,c("CPI_daily", "WeekendFlag", "Festivity", "Trend", "PromoFlag")]))
dataset <- df[,c("CPI_daily", "WeekendFlag", "Festivity", "Trend", "PromoFlag")]
dataset$PromoFlag <- rep(0, length(dataset$PromoFlag))
dataset$PromoFlag <- as.factor(dataset$PromoFlag)

## produce forecasts
myforecasts <- forecast::forecast(baseline_Sarimax, xreg=data.matrix(dataset))
baseline <- as.data.frame(cbind(myforecasts$fitted, as.character(Date$Date)))
colnames(baseline) <- c("Forecasts", "Date")
baseline$Date <- as.POSIXct(baseline$Date, format = "%Y-%m-%d",
                                tz = time_at_tz(Sys.timezone(location = TRUE)))
baseline$Forecasts <- as.numeric(baseline$Forecasts)
baseline$TrueValues <- df$TotVolumes

# Calculating elasticity
dates_elasticity <- df$Date[which(df$PromoFlag == 1)] 
Actual <- df %>% filter(Date %in% dates_elasticity) %>%  select(TotVolumes) 
Base <- baseline %>% filter(Date %in% dates_elasticity) %>%  select(Forecasts) 
Uplift <- Actual - Base
Discount <- df %>% filter(Date %in% dates_elasticity) %>% select(SumDiscounts)
Elasticity <- -Uplift/Discount
Dataset <- as.data.frame(cbind(Elasticity, dates_elasticity))
colnames(Dataset) <- c("Elasticity", "Date")
return(Dataset)
}


```

```{r For each product}
# The products
# 49340, 49341, 49333 and 49329
Elasticity49340 <- elasticity("49340")
Elasticity49341 <- elasticity("49341") 
Elasticity49333 <- elasticity("49333") 
Elasticity49329 <- elasticity("49329") # This returns error because according to our calculations based on the definitions given to us, no promotions have been performed !

# Note: Ignore the error that is returned by the function!
```

