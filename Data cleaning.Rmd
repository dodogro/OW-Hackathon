---
title: "Data Cleaning"
output: html_notebook
---
Setting path
NOTE: In order to run the script smoothly we recommend to have saved the folder
containing all the data sets in a separate folder called "Data-OW"
```{r Path Setting}
path = "../Data-OW/"
```

Importing libraries
```{r Importing Libraries}
pacman::p_load(readxl,lubridate,dplyr,timechange,stringr,shinydashboard)
```

___________________________________________________
# DimProduct dataset

Setting the working directory and importing the datasets
```{r Laoding Product.df}
head(product.df <- read.csv(paste0(path,"Hackathon_DimProduct_SAN_vShared.csv"), 
                       header = TRUE), 10)
str(product.df)
```

Cleaning ProductKey Column
Note on RegEx: (i?) is used to render the match case insensitive
```{r Cleaning ProductKey}
product.df$ProductKey <- gsub("(i?)key_", "", product.df$ProductKey)
length(product.df$ProductKey)

# OK
```

Cleaning Product Sub-Category column. Indeed, lv2. has some categories that needs to be transformed from lower case to upper case before the substitution.
Note on RegEx used: - (\\w*) = takes every word up to infinite times
                    - (\\s)  = considers the first space present in the string
                    - Combination of the two = Take all the words before a space (included)
```{r Cleaing Product Category}
product.df$ProductCategory_Lvl1 <- toupper(gsub("(\\w*\\s)", "", 
                                        product.df$ProductCategory_Lvl1))

product.df$ProductCategory_Lvl2 <- toupper(gsub("(\\w*\\s)", "", 
                                        product.df$ProductCategory_Lvl2))

# toUpper has been used in order as remedy to the difference in case present
# in the vectors
```

Transforming categories into factors
```{r Factorization}
product.df$ProductCategory_Lvl1 <- as.factor(product.df$ProductCategory_Lvl1)
product.df$ProductCategory_Lvl2 <- as.factor(product.df$ProductCategory_Lvl2)
```

____________________
Quick exploration of categories
```{r Exploration}
table(product.df$ProductCategory_Lvl1) # Only Category A
```

At lv.1 only A category is present in the dataset

```{r Exploration}
table(product.df$ProductCategory_Lvl2)
```
Product suppliers
```{r Exploration}
length(unique(product.df$SupplierKey))
```
There are 17 Product suppliers

________________________________________________________________________________
# CPI dataset

```{r Loaging CPI.df} 
head(cpi.df <- read_xlsx(paste0(path, "Consumer Price Index_vShared.xlsx")))
```
Understanding type of variables
```{r Overview}
str(cpi.df)
```

Date columns are already in POSIXct format, no need for change

```{r Overview}
summary(cpi.df)
```
Most of monthly data are missing, thus the information must be reconstructed starting from the daily data. We have noticed that the monthly CPI index is constructed 
by simply taking the first-of-the-month index. Is it correct though? 

Idea: creating the correspondence between month and year, and computing the monthly CPI as the mean of the daily CPI

```{r Reproducing CPI monthly as daily average}
# Creating Date_Monthly and CPI_monthly columns
head(cpi.df1 <- cpi.df %>% 
     group_by(month(Date_daily), year(Date_daily)) %>% 
     mutate(Date_monthly1 = paste0(year(Date_daily),"-",month(Date_daily),"-01"),
             CPI_monthly1 = mean(CPI_daily)))

cpi.df1 <- cpi.df1 %>% 
  ungroup() %>% 
  select(Date_monthly1, CPI_monthly1, Date_daily, CPI_daily)

# Creating the date format for Date_monthly1
cpi.df1$Date_monthly1 <- as.POSIXct(cpi.df1$Date_monthly1)

# Correcting columns name
colnames(cpi.df1) <- c("Date_monthly",
                       "CPI_monthly",
                       "Date_daily",
                       "CPI_daily")
```

Clearing the environment and final check
```{r Environment Clearnance}
# For sake of keeping the same data sets' names
cpi.df <- cpi.df1
remove(cpi.df1)

# Final check
str(cpi.df)

# OK
```

IMPORTANT NOTE:
There is a slight difference in monthly CPI computed as the mean of daily values and the one provided by the data due to the reason stated above. 

___________________________________________________
# Promotion dataset

```{r Laoding Promotion.df}
head(promotion.df <- read.table(paste0(path,"Hackathon_DimPromotion_SAN_vShared.csv"), 
                                header = TRUE,
                                sep = ","))
str(promotion.df)
```

Transforming PromotionKey into character (might be transformed into factor later)
```{r Characterization}
promotion.df$PromotionKey <- as.character(promotion.df$PromotionKey)
```

Transforming Promotion Dates into POSIXct formats
```{r Dates as.Date}
promotion.df$PromotionStartDate <- as.POSIXct(promotion.df$PromotionStartDate,
                                              format = "%m/%d/%Y")

promotion.df$PromotionEndDate <- as.POSIXct(promotion.df$PromotionEndDate,
                                            format = "%m/%d/%Y")
```

Transforming promotion mechanics into factor
```{r Factorization}
promotion.df$PromoMechanic <- as.factor(promotion.df$PromoMechanic)
table(promotion.df$PromoMechanic)
```
There are 15 promotion types + 1 unknown

```{r Overview}
summary(promotion.df)
```
No missing values

OK

____________________________________________-
# Store Dataset

```{r Laoding Store.df}
head(store.df <- read.table(paste0(path, 
                                   "Hackathon_DimStore_SAN_vShared.csv"), 
                           header = TRUE,
                           sep = ","))
```

```{r Overview}
str(store.df)
```

Transforming StoreKey and DistributionChannel into factors
```{r Factorization}
store.df$StoreKey <- as.factor(store.df$StoreKey)
store.df$DistributionChannel <- as.factor(store.df$DistributionChannel)
```


Adjusting StoreType and transforming it into factor
Note on RegEx: (\S+\s\S+) serves two take the first two words in the string, where \\S+ is the negation of \s, thus taking all the words excluding the space and \\s considers exactly the spaces. The combination takes thus exactly the first two words before a second space 
```{r Cleaning miswritten data entries}
store.df$StoreType <- gsub("(\\S+\\s\\S+)", "", store.df$StoreType)
store.df$StoreType <- as.factor(store.df$StoreType)
```

Adjusting Region_lvl 1 and 2 and transforming into factors
Note on RegEx: - [A-Z](?!.*[A-Z].* takes just the last capital letter
               - \\d+ is takes just the first group of number
```{r Cleaning miswritten data entries}
store.df$Region_Lvl1 <- str_extract(store.df$Region_Lvl1, "[A-Z](?!.*[A-Z].*)")
store.df$Region_Lvl2 <- str_extract(store.df$Region_Lvl2, "\\d+")

store.df$Region_Lvl1 <- as.factor(store.df$Region_Lvl1)
store.df$Region_Lvl2 <- as.factor(store.df$Region_Lvl2)
```

Final check
```{r Exploration}
table(store.df$Region_Lvl1)
as.data.frame(table(store.df$Region_Lvl2))

```

OK

_____________________________________
# Trasaction Dataset

```{r Laoding Transaction.df}
head(transaction.df <- read.table(paste0(path,
                       "Hackathon_FactSalesTransactionDATES_vShared.csv"),
                                  header = TRUE,
                                  sep = ","))
```



```{r Overview}
str(transaction.df)
```

Trasforming TransactionDate into POSIXct format (it takes a while)
```{r Dates as.Date}
head(transaction.df$TransactionDate <- as.POSIXct(transaction.df$TransactionDate, 
                                              format = "%Y-%m-%d",
                                              tz = time_at_tz(
                                              Sys.timezone(location = TRUE))))

```

Transforming DayOfWeek, WeekendFlag, StoreKey and ProductKey into factors
```{r Factorization}
transaction.df$DayOfWeek <- as.factor(transaction.df$DayOfWeek)
transaction.df$WeekendFlag <- as.factor(transaction.df$WeekendFlag)
transaction.df$StoreKey <- as.factor(transaction.df$StoreKey)
transaction.df$ProductKey <- as.factor(transaction.df$ProductKey)
```

```{r Overview}
summary(transaction.df)
```

# 23978 missing values
Check what 23978 missing values are treated as characters
```{r Testing}
test1 <- transaction.df$TransactionDate
test2 <- transaction.df$TransactionDate

test1 <- as.POSIXct(test1,
                    format = "%Y-%m-%d",
                    tz = "")

verifica <- test2[which(is.na(test1))]

head(verifica)
```

Testing if the same problem is replicated also for other character variables different from date
```{r Looking for the NAs}
names(transaction.df)
length(which(transaction.df$DayOfWeek == ""))
length(which(transaction.df$WeekendFlag == ""))
```

A recurrent pattern of "" for 23978 observation is present
-> Deleting those observations from the dataset

```{r Removing "" values}
transaction.df <- transaction.df %>% 
  filter(as.character(TransactionDate) != "")
```



Checking again the summary
```{r Overview}
summary(transaction.df)
```
There are still 72125 missing values in ActualSales

# 72125 missing ActualSales

```{r Testing}
test1 <- transaction.df %>% 
  filter(is.na(transaction.df$ActualSales))

summary(test1)
```

By comparing the two summaries we can see that the full dataset entails SalesDiscount both negative and positive while the subset of transactions where the "ActualSales" are missing has only negative discounts.
-> We can derive: ActualSales = RetailFullPrice + (-SalesDiscount)
since SalesDiscount for missing ActualSales has only negative values

We will later explore positive values of sales discount

Deriving missing ActualSales
```{r NAs imputation}
head(transaction.df$ActualSales[is.na(transaction.df$ActualSales)] <- transaction.df$RetailFullPrice[is.na(transaction.df$ActualSales)] 
+ transaction.df$SalesDiscount[is.na(transaction.df$ActualSales)])
```

Checking again the summary
```{r Overivew}
summary(transaction.df)
```
No more missing values 

OK
________________________________________________________________________________
# Trasaction Promotion Data set
```{r Laoding Transaction.Promotion.df}
head(transaction.promotion.df <-read.table(paste0(path,
                                             "Hackathon_FactSalesTransactionPromotion_vShared.csv"),
                                       header = TRUE,
                                       sep = ","))
```

Transforming TransactionDate into POSIXct format
```{r Dates as.Date}
transaction.promotion.df$TransactionDate <- as.POSIXct(transaction.promotion.df$TransactionDate,
                                                       format = "%Y-%m-%d")

```

Transforming StoreKey, ProductKey and Promotion Key into factors
```{r Factorization}
transaction.promotion.df$StoreKey <- as.factor(transaction.promotion.df$StoreKey)
transaction.promotion.df$ProductKey <- as.factor(transaction.promotion.df$ProductKey)
transaction.promotion.df$PromotionKey <- as.factor(transaction.promotion.df$PromotionKey)
```

```{r Overview}
summary(transaction.promotion.df)
```
OK
_____________________________________
# Holiday

```{r Laoding Holiday.df}
head(holiday.df <- read.table(paste0(path,"Hackathon_HolidaysMY_vShared.csv"), 
                                       header = TRUE,
                                       sep = ","))
```

Some information about holidays, we should search each period and merge the information


Merging data sets....
Note: Due to the immense data frame size, we are forced to work piecewise, otherwise
our machines will not able to function well. 
We will subset the data frames in years in order to keep them more manageable
Note: Since the transactions go from 2020.01.01 to 2022.12.31, it has been 
decided to remove the dates that were present concerning dates not in the 
scrutinized timespan

```{r Date as.Date}
cpi.df.period <- cpi.df[between(cpi.df$Date_daily, as.POSIXct("2020-01-01"), as.POSIXct("2022-12-31")),]

promotion.df.period <- promotion.df[between(promotion.df$PromotionStartDate, as.POSIXct("2020-01-01"), as.POSIXct("2022-12-31")),]

```
Now we will split the data frame transaction into 2020, 2021, and 2022
```{r}
# Creating a function "splitting_years" since it will be used multiple times 

splitting_years <- function(transaction.df,start,end){
        return(transaction.df[between(transaction.df$TransactionDate, 
               as.POSIXct(start), 
               as.POSIXct(end)),])}
        

# For transactions
transactions2020 <- splitting_years(transaction.df, "2020-01-01", "2020-12-31")
transactions2021 <- splitting_years(transaction.df, "2021-01-01", "2021-12-31")
transactions2022 <- splitting_years(transaction.df, "2022-01-01", "2022-12-31")

```
