---
title: "EDA"
output: html_notebook
---

```{r}
pacman::p_load(ggplot2, tidyverse, lubridate, packcircles, viridis, ggiraph,
               lattice, gcookbook, tidyr)
```

```{r}
path = "../Data-OW/"
load(file = paste0(path,"MergedData.RData"))
df <- transaction.df
```

# Checking summaries
```{r Summary 2020}
summary(df)
```

# Check for drastic data changes
We expect the same order of magnitude in the number of transaction recorded for each month during the three years. If that is not the case, probably there has been some mistakes in the data collection process.

```{r}
trans.number <- df %>% 
  group_by(Month = month(TransactionDate), Year = year(TransactionDate)) %>% 
  summarise(trans.record = n()) %>% 
  arrange(Year)

ggplot(data = trans.number, aes(x = Month, y = trans.record, group = Year,
                                colour = factor(Year))) +
  geom_line() +
  geom_point() + 
  scale_x_discrete(limits = trans.number$Month) +
  ylab("Number of transactions")

```
Huge decrease in April 2020 with 151128 transactions considered a mean equal to 313250.6 monthly transactions

Going deep into April 2020
```{r}
april2020 <-  df %>% 
  filter(year(TransactionDate) == 2020) %>% 
  filter(month(TransactionDate) == 4) %>% 
  group_by(Day = day(TransactionDate)) %>% 
  summarise(trans.recorded = n())

view(april2020)
```

There are no holes in data recordings apparently, just low values
Filtering by month number it's possible to check how many stores made a sale during that particular month compared to the total number of stores that made at least one sale during 2020

```{r Number of stores that made a sale}
month2020.wide <- df %>% 
  filter(year(TransactionDate) == 2020) %>% 
  filter(month(TransactionDate) == 4)

length(unique(month2020.wide$StoreKey))
length(unique(df[year(df$TransactionDate) == 2020,]$StoreKey))
```
In March (3) and May (5) 2020, respectively 555 and 550 stores made at least one sale, but in April just 513 stores made a sale during that period. Possible Covid-related issues, considering that during the year, the number of active stores (stores that made at least one sale during the year) were 601.


# Days of the week

```{r Checking relative frequencies}
# Dropping unused level
transactions2020$DayOfWeek <- droplevels(transactions2020$DayOfWeek)
transactions2021$DayOfWeek <- droplevels(transactions2021$DayOfWeek)
transactions2022$DayOfWeek <- droplevels(transactions2022$DayOfWeek)
df$

# Re-ordering levels
transactions2020$DayOfWeek <- factor(transactions2020$DayOfWeek,
                                     levels=c('Monday', 'Tuesday', 'Wednesday',
                                              'Thursday', 'Friday', 'Saturday',
                                              'Sunday'))

transactions2021$DayOfWeek <- factor(transactions2021$DayOfWeek,
                                     levels=c('Monday', 'Tuesday', 'Wednesday',
                                              'Thursday', 'Friday', 'Saturday',
                                              'Sunday'))

transactions2022$DayOfWeek <- factor(transactions2022$DayOfWeek,
                                     levels=c('Monday', 'Tuesday', 'Wednesday',
                                              'Thursday', 'Friday', 'Saturday',
                                              'Sunday'))
# Checking frequencies
table(transactions2021$DayOfWeek)
table(transactions2020$DayOfWeek)
table(transactions2022$DayOfWeek)

dayoftheweek.plot <- as.data.frame(rbind(table(transactions2020$DayOfWeek),
                                           table(transactions2021$DayOfWeek),
                                           table(transactions2022$DayOfWeek))) %>% 
  gather(Day, Frequency, Monday:Sunday)

dayoftheweek.plot$Year <- rep(c("2020", "2021", "2022"), 7)

dayoftheweek.plot <- dayoftheweek.plot %>% 
  group_by(Year) %>% 
  mutate(rel.frequency = Frequency/sum(Frequency))

dayoftheweek.plot$Day <- factor(dayoftheweek.plot$Day,
                                levels=c('Monday', 'Tuesday', 'Wednesday',
                                         'Thursday', 'Friday', 'Saturday',
                                         'Sunday'))

ggplot(dayoftheweek.plot, aes(x = Day, y = rel.frequency, fill = Year)) +
  geom_bar(position = "stack", stat = "identity") +
  labs(x = "Category", y = "Relative frequency")
```

Transaction more or less disstributed throughout the week with a peak from Friday to Sunday



## Weekend Flag
```{r WeekendFlag}
transactions2020$WeekendFlag <- droplevels(transactions2020$WeekendFlag)
transactions2021$WeekendFlag <- droplevels(transactions2021$WeekendFlag)
transactions2022$WeekendFlag <- droplevels(transactions2022$WeekendFlag)

table(transactions2020$WeekendFlag)
table(transactions2021$WeekendFlag)
table(transactions2022$WeekendFlag)
```

# Stores overview

```{r Preparing dataset}
# Select the year
yr <- "2020"

store.summary <- rbind(transactions2020, transactions2021, transactions2022) %>% 
  select(StoreKey, StoreType, Region_Lvl1, Region_Lvl2, ActualSales, TransactionDate) %>% 
  filter(year(TransactionDate) == yr) %>% 
  group_by(StoreKey, StoreType, Region_Lvl1, Region_Lvl2) %>% 
  summarise(revenues = sum(ActualSales)) %>% 
  mutate(txt = paste("Store: ",StoreKey, "\n",
                     "Yearly sales: ", round(revenues/1000, digits = 0),"kâ‚¬", "\n",
                     "Region lvl.1: ", Region_Lvl1, "\n",
                     "Region lvl.2: ", Region_Lvl2)) %>% 
  arrange(desc(revenues)) %>% 
  ungroup()

# Preparing variables
store.summary$StoreKey <- as.character(store.summary$StoreKey)
```

```{r Packed Bubble Chart}
# Generating Layout
packing <- circleProgressiveLayout(store.summary$revenues, sizetype = "area")
data <- cbind(store.summary, packing)
data.gg <- circleLayoutVertices(packing, npoints = 50)

# Plot
p <- ggplot() +
  geom_polygon_interactive(data = data.gg,
                           aes(x = x, y = y, group = id, fill = id,
                               tooltip = data$txt[id], data_id = id),
                           colour = "black", alpha = 0.6) +
  scale_fill_viridis() +
  geom_text(data = data,
            aes(x = x, y = y, label = StoreKey),
            size = 2, colour = "black") +
  theme_void() + 
  theme(legend.position = "none") +
  coord_equal()

# Interactive
widg <- ggiraph(ggobj = p, width_svg = 7, height_svg = 7)
widg
```

How many stores opened or closed from 2020?
```{r Stores opened/closed}
stores.2020 <- unique(transactions2020$StoreKey)
stores.2022 <- unique(transactions2022$StoreKey)

# Stores closed
stores.2020[!(stores.2020 %in% stores.2022)]
print(paste(length(stores.2020[!(stores.2020 %in% stores.2022)]), "stores closed from 2020",
            sep = " "))
# Stores opened
stores.2022[!(stores.2022 %in% stores.2020)]
print(paste(length(stores.2022[!(stores.2022 %in% stores.2020)]), "stores opened from 2020"))

remove(stores.2020, stores.2022)
```

# ProductCategory
```{r Exploring tables}
table(transactions2020$ProductCategory_Lvl2)
table(transactions2022$ProductCategory_Lvl2)
```

# Product Category

```{r Preparing data}
# Select product category
prod.cat <- c("AA", "AB", "AC", "AD", "AE")

transactions.sag <- rbind(transactions2020, transactions2021, transactions2022) %>% 
  select(TransactionDate, ActualSales, ProductCategory_Lvl2) %>% 
  filter(ProductCategory_Lvl2 %in% prod.cat) %>% 
  group_by(ProductCategory_Lvl2) %>% 
  arrange(TransactionDate) %>% 
  mutate(cum_rev = cumsum(ActualSales))

```

```{r Preparing the dataset}
ggplot(data = transactions.sag, aes(x = TransactionDate, y = cum_rev,
                                    fill = ProductCategory_Lvl2)) +
  labs(fill = "Product Category\nLvl. 2", 
       x = "Transaction Date",y = "Cumulative revenues" ) +
  geom_area(color = "black", linewidth = 0.2, alpha = 0.6)
```

AD products are irrelevant when compared to other categories, AE shows a really slow growth, while AA, AB, AC are the best categories in terms of volumes and growth.

# Distribution channels

```{r Preparing the dataset}
# Select distribution channel
dist.channel <- c("Physical", "Online")

dist.channel.sag <- rbind(transactions2020, transactions2021, transactions2022) %>% 
  select(TransactionDate, ActualSales, DistributionChannel) %>% 
  filter(DistributionChannel %in% dist.channel) %>% 
  group_by(DistributionChannel) %>% 
  arrange(TransactionDate) %>% 
  mutate(cum_rev = cumsum(ActualSales))

```

```{r Preparing the dataset}
ggplot(data = dist.channel.sag, aes(x = TransactionDate, y = cum_rev,
                                    fill = DistributionChannel)) +
  labs(fill = "Product Category\nLvl. 2", 
       x = "Transaction Date",y = "Cumulative revenues" ) +
  geom_area(color = "black", linewidth = 0.2, alpha = 0.6)
```

Online distribution channel is a very narrow revenues source with low growth


# Regional distribution

```{r Preparing the dataset}
# Select regions to exclude
regions.exclude.Lvl1 <- c("") # Lvl 1 regions to exclude
regions.exclude.Lvl2 <- c("") # Lvl 2 regions to exclude

reg.distribution.sag <- rbind(transactions2020, transactions2021, transactions2022) %>% 
  select(TransactionDate, ActualSales, Region_Lvl2, Region_Lvl1) %>% 
  filter(!(Region_Lvl1 %in% regions.exclude.Lvl1) | 
           !(Region_Lvl2 %in% regions.exclude.Lvl2)) %>% 
  group_by(Region_Lvl2, Region_Lvl1) %>% 
  arrange(TransactionDate) %>% 
  mutate(cum_rev = cumsum(ActualSales))
```


```{r Empty regions}
empty.regions <- rbind(transactions2021, transactions2022) %>% 
  filter(is.na(Region_Lvl2))
view(empty.regions)
```

StoreKey = 0 is linked to the online distribution channel

# Prices
```{r Negative actual sales}
negative.actual.sales.2020 <- transactions2020 %>% 
  filter(ActualSales <= 0)
negative.actual.sales.2021 <- transactions2021 %>% 
  filter(ActualSales <= 0)
negative.actual.sales.2022 <- transactions2022 %>% 
  filter(ActualSales <= 0)
negative.actual.sales <- rbind(negative.actual.sales.2020,
                               negative.actual.sales.2021,
                               negative.actual.sales.2022)

remove(negative.actual.sales.2020, 
       negative.actual.sales.2021,
       negative.actual.sales.2022)

summary(negative.actual.sales)
```

```{r Positive discounts}
positive.discounts <- rbind(transactions2020, transactions2021, transactions2022) %>% 
  filter(SalesDiscount > 0)
view(positive.discounts)
```

71 observations with positive discounts, possibly due to errors or price corrections


```{r Unitary price distribution}
outliers.actualsales <- rbind(transactions2020, transactions2021, transactions2022) %>% 
  filter(RetailFullPrice > 0 & UnitVolume > 0) %>% 
  mutate(unitary.price = RetailFullPrice/UnitVolume)

summary(outliers.actualsales$unitary.price)
```

```{r}
outliers.transactions <- outliers.actualsales %>% 
  filter(unitary.price >= 41)
```


```{r Plotting price distribution}
retail.price <- outliers.actualsales %>% 
  select(TransactionDate, ProductCategory_Lvl2, unitary.price) %>% 
  group_by(Month = month(TransactionDate), Year = year(TransactionDate), ProductCategory_Lvl2) %>% 
  summarise(avg.price = mean(unitary.price)) %>% 
  mutate(time.interval = as.POSIXct(paste(Year, Month, "01", sep = "-"), 
                                    format = "%Y-%m-%d"))

ggplot(data = retail.price, aes(x = time.interval, y = avg.price, group = ProductCategory_Lvl2,
                                colour = factor(ProductCategory_Lvl2))) +
  geom_line() +
  geom_point() +
  ylab("Average monthly category price") +
  xlab("Date")

```
Huge jump in the average unitary price ticket of categories AD and AE starting from July 2021. A deeper exploration is needed in order to check if the price of the items sold in the categories changed or it is due to an increase in selling of higher priced products belonging to the specific category.

```{r Pareto analysis}
#################################################
# Select the timeframe of analysis
time.interval <- interval(as.POSIXct("2022-01-01",
                                     format = "%Y-%m-%d",
                                     tz = time_at_tz(Sys.timezone(location = TRUE))),
                          as.POSIXct("2022-12-31",
                                     format = "%Y-%m-%d",
                                     tz = time_at_tz(Sys.timezone(location = TRUE))))

# Select the category: AA, AB, AC, AD, AE
category.filter <- c("AC")

# Select the top N products to check
topN <- 10

#################################################

# Creating the pareto dataset for the plot
pareto.analysis <- rbind(transactions2020, transactions2021, transactions2022) %>% 
  filter(ProductCategory_Lvl2 %in% category.filter &
           TransactionDate %within% time.interval) %>% 
  select(ProductKey, ProductCategory_Lvl2, ActualSales) %>% 
  group_by(ProductKey, ProductCategory_Lvl2) %>% 
  summarise(tot.revenues = sum(ActualSales)) %>% 
  ungroup() %>% 
  arrange(desc(tot.revenues)) %>% 
  mutate(perc.revenues = cumsum(tot.revenues)/sum(tot.revenues))

#Creating the dataset with the top N products
topN.products <- rbind(transactions2020, transactions2021, transactions2022) %>% 
  filter(ProductKey %in% pareto.analysis$ProductKey[1:topN])

# Pareto analysis plot
ggplot(data = pareto.analysis, aes(x = factor(ProductKey, levels = ProductKey), y = perc.revenues)) +
  geom_bar(stat = "identity", aes(fill = pareto.analysis$tot.reveneues, alpha = 0.6)) +
  geom_hline(yintercept = 0.75, colour = "blue") +
  geom_hline(yintercept = 0.90, colour = "red") +
  geom_point() +
  geom_path() +
  scale_x_discrete(breaks = pareto.analysis$ProductKey) +
  ylab("Cumulated revenues") +
  xlab("ProductKey")

# + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) 
# Not visible with many Product Keys
```




