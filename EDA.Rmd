---
title: "EDA"
output: html_notebook
---

```{r Packages Loading}
pacman::p_load(ggplot2, tidyverse, lubridate, packcircles, viridis, ggiraph,
               lattice, gcookbook, tidyr, timechange, ggstream)

options(scipen=999)
```

```{r Loading Dataset}
path = "../Data-OW/"
load(file = paste0(path,"MergedData.RData"))
df <- transaction.df
```

```{r Summary 2020}
summary(df)
```

# Check for drastic data changes
We expect the same order of magnitude in the number of transaction recorded for each month during the three years. If that is not the case, probably there has been some mistakes in the data collection process.

```{r Transaction Quantities}
trans.number <- df %>% 
  group_by(Month = month(TransactionDate), Year = year(TransactionDate)) %>% 
  summarise(trans.record = n()) %>% 
  arrange(Year)

ggplot(data = trans.number, aes(x = Month, y = trans.record, group = Year,
                                colour = factor(Year))) +
  geom_line() +
  geom_point() + 
  scale_x_discrete(limits = trans.number$Month) +
  ylab("Number of transactions")

```
Huge decrease in April 2020 with 151128 transactions considered a mean equal to 313250.6 monthly transactions

Going deep into April 2020
```{r April deep dive}
april2020 <-  df %>% 
  filter(year(TransactionDate) == 2020) %>% 
  filter(month(TransactionDate) == 4) %>% 
  group_by(Day = day(TransactionDate)) %>% 
  summarise(trans.recorded = n())

view(april2020)
```

There are no "missing" data apparently, just low values.
Filtering by month number it's possible to check how many stores made a sale during that particular month compared to the total number of stores that made at least one sale during 2020

```{r Number of stores that made a sale}
month2020.wide <- df %>% 
  filter(year(TransactionDate) == 2020) %>% 
  filter(month(TransactionDate) == 4)

length(unique(month2020.wide$StoreKey))
length(unique(df[year(df$TransactionDate) == 2020,]$StoreKey))
```
In March (3) and May (5) 2020, 555 and 550 stores made at least one sale respectively. In April just 513 stores made a sale during that period. Possible Covid-related issues, considering that during the year, the number of active stores (stores that made at least one sale during the year) were 601.

# Days of the week

```{r Checking relative frequencies}
# Re-ordering levels

df$DayOfWeek <- factor(df$DayOfWeek,
                       levels=c('Monday', 'Tuesday', 'Wednesday',
                                'Thursday', 'Friday', 'Saturday',
                                'Sunday'))

# Checking frequencies
table(df$DayOfWeek)

dayoftheweek.plot <- df %>% 
  group_by(year(TransactionDate), df$DayOfWeek) %>% 
  summarise(Frequency = n())


dayoftheweek.plot$Year <- rep(c("2020", "2021", "2022"), 7)

dayoftheweek.plot <- dayoftheweek.plot %>% 
  group_by(Year) %>% 
  mutate(rel.frequency = Frequency/sum(Frequency))

dayoftheweek.plot$Day <- factor(dayoftheweek.plot$`df$DayOfWeek`,
                                levels=c('Monday', 'Tuesday', 'Wednesday',
                                         'Thursday', 'Friday', 'Saturday',
                                         'Sunday'))

ggplot(dayoftheweek.plot, aes(x = Day, y = rel.frequency, fill = Year)) +
  geom_bar(position = "stack", stat = "identity") +
  labs(x = "Category", y = "Relative frequency")
```

Transaction more or less disstributed throughout the week with a peak from Friday to Sunday

## Weekend Flag
```{r WeekendFlag}
table(df$WeekendFlag)
```

# Stores overview

```{r Preparing dataset for the stores}
# Select the year
yr <- "2020"

store.summary <- df %>% 
  select(StoreKey, StoreType, Region_Lvl1, Region_Lvl2, ActualSales, TransactionDate) %>% 
  filter(year(TransactionDate) == yr) %>% 
  group_by(StoreKey, StoreType, Region_Lvl1, Region_Lvl2) %>% 
  summarise(revenues = sum(ActualSales)) %>% 
  mutate(txt = paste("Store: ",StoreKey, "\n",
                     "Yearly sales: ", round(revenues/1000, digits = 0),"kâ‚¬", "\n",
                     "Region lvl.1: ", Region_Lvl1, "\n",
                     "Region lvl.2: ", Region_Lvl2)) %>% 
  arrange(desc(revenues)) %>% 
  ungroup()

# Preparing variables
store.summary$StoreKey <- as.character(store.summary$StoreKey)
```

```{r Packed Bubble Chart}
# Generating Layout
packing <- circleProgressiveLayout(store.summary$revenues, sizetype = "area")
data <- cbind(store.summary, packing)
data.gg <- circleLayoutVertices(packing, npoints = 50)

# Plot
p <- ggplot() +
  geom_polygon_interactive(data = data.gg,
                           aes(x = x, y = y, group = id, fill = id,
                               tooltip = data$txt[id], data_id = id),
                           colour = "black", alpha = 0.6) +
  scale_fill_viridis() +
  geom_text(data = data,
            aes(x = x, y = y, label = StoreKey),
            size = 2, colour = "black") +
  theme_void() + 
  theme(legend.position = "none") +
  coord_equal()

# Interactive
widg <- ggiraph(ggobj = p, width_svg = 7, height_svg = 7)
widg
```

How many stores opened or closed from 2020?
```{r Stores opened/closed}
stores.2020 <- unique(df$StoreKey[df$TransactionDate < as.POSIXct("2021-01-01",format = "%Y-%m-%d", tz = "")])
stores.2022 <- unique(df$StoreKey[df$TransactionDate > as.POSIXct("2022-01-01",format = "%Y-%m-%d", tz = "")])

# Stores closed
stores.2020[!(stores.2020 %in% stores.2022)]
print(paste(length(stores.2020[!(stores.2020 %in% stores.2022)]), "stores closed from 2020",
            sep = " "))
# Stores opened
stores.2022[!(stores.2022 %in% stores.2020)]
print(paste(length(stores.2022[!(stores.2022 %in% stores.2020)]), "stores opened from 2020"))

remove(stores.2020, stores.2022)
```

# ProductCategory
```{r Exploring tables}
table(df$ProductCategory_Lvl2)
```

# Product Category

```{r Preparing data}
# Select product category
prod.cat <- c("AA", "AB", "AC", "AD", "AE")

transactions.sag <- df %>% 
  select(TransactionDate, ActualSales, ProductCategory_Lvl2) %>% 
  filter(ProductCategory_Lvl2 %in% prod.cat) %>% 
  group_by(ProductCategory_Lvl2) %>% 
  arrange(TransactionDate) %>% 
  mutate(cum_rev = cumsum(ActualSales))

```

```{r Plot}
ggplot(data = transactions.sag, aes(x = TransactionDate, y = cum_rev,
                                    fill = ProductCategory_Lvl2)) +
  labs(fill = "Product Category\nLvl. 2", 
       x = "Transaction Date",y = "Cumulative revenues" ) +
  geom_area(color = "black", linewidth = 0.2, alpha = 0.6)
```

AD products are irrelevant when compared to other categories, AE shows a really slow growth, while AA, AB, AC are the best categories in terms of volumes and growth.

```{r}
cat.performances <- transactions.sag %>% 
  group_by(ProductCategory_Lvl2, Year = year(TransactionDate)) %>% 
  summarise(total.sales = sum(ActualSales)) %>% 
  arrange(Year)

sum(cat.performances$total.sales[cat.performances$Year == 2022 & (cat.performances$ProductCategory_Lvl2 == "AA" | cat.performances$ProductCategory_Lvl2 == "AB" | cat.performances$ProductCategory_Lvl2 == "AC")]) / sum(cat.performances$total.sales[cat.performances$Year == 2022])
```


# Distribution channels

```{r Preparing the dataset for the distribution channel}
# Select distribution channel
dist.channel <- c("Physical", "Online")

dist.channel.sag <- df %>% 
  select(TransactionDate, ActualSales, DistributionChannel) %>% 
  filter(DistributionChannel %in% dist.channel) %>% 
  group_by(DistributionChannel) %>% 
  arrange(TransactionDate) %>% 
  mutate(cum_rev = cumsum(ActualSales))

ggplot(data = dist.channel.sag, aes(x = TransactionDate, y = cum_rev,
                                    fill = DistributionChannel)) +
  labs(fill = "Distribution channel", 
       x = "Transaction Date",y = "Cumulative revenues" ) +
  geom_area(color = "black", linewidth = 0.2, alpha = 0.6)
```

Online distribution channel is a very narrow revenues source with low growth

```{r Online Sales Share}
sum(dist.channel.sag$ActualSales[year(dist.channel.sag$TransactionDate) == 2022 & dist.channel.sag$DistributionChannel == "Online"]) / sum(dist.channel.sag$ActualSales[year(dist.channel.sag$TransactionDate) == 2022]) 
```


# Regional distribution

```{r Preparing the dataset}
# Select regions to exclude
regions.exclude.Lvl1 <- c("") # Lvl 1 regions to exclude
regions.exclude.Lvl2 <- c("") # Lvl 2 regions to exclude

reg.distribution.sag <- df %>% 
  select(TransactionDate, ActualSales, Region_Lvl2, Region_Lvl1) %>% 
  filter(!(Region_Lvl1 %in% regions.exclude.Lvl1) | 
           !(Region_Lvl2 %in% regions.exclude.Lvl2)) %>% 
  group_by(Region_Lvl2, Region_Lvl1) %>% 
  arrange(TransactionDate) %>% 
  mutate(cum_rev = cumsum(ActualSales))
```


```{r Empty regions}
empty.regions <- df %>% 
  filter(is.na(Region_Lvl2))
view(empty.regions)
```

StoreKey = 0 is linked to the online distribution channel

# Prices
```{r Negative actual sales}
negative.actual.sales <- df %>% 
  filter(ActualSales <= 0)

summary(negative.actual.sales)
```

```{r Positive discounts}
positive.discounts <- df %>% 
  filter(SalesDiscount > 0)
view(positive.discounts)
```

71 observations with positive discounts, possibly due to errors or price corrections


```{r Unitary price distribution}
outliers.actualsales <- df %>% 
  filter(RetailFullPrice > 0 & UnitVolume > 0) %>% 
  mutate(unitary.price = RetailFullPrice/UnitVolume)

summary(outliers.actualsales$unitary.price)
```

```{r}
outliers.transactions <- outliers.actualsales %>% 
  filter(unitary.price >= 41)
```


```{r Plotting price distribution}
retail.price <- outliers.actualsales %>% 
  select(TransactionDate, ProductCategory_Lvl2, unitary.price) %>% 
  group_by(Month = month(TransactionDate), Year = year(TransactionDate), ProductCategory_Lvl2) %>% 
  summarise(avg.price = mean(unitary.price)) %>% 
  mutate(time.interval = as.POSIXct(paste(Year, Month, "01", sep = "-"), 
                                    format = "%Y-%m-%d"))

ggplot(data = retail.price, aes(x = time.interval, y = avg.price, group = ProductCategory_Lvl2,
                                colour = factor(ProductCategory_Lvl2))) +
  geom_line() +
  geom_point() +
  ylab("Average monthly category price") +
  xlab("Date")

```
Huge jump in the average unitary price ticket for categories AD and AE starting from July 2021. A deeper exploration is needed in order to check if the price of the items sold in the categories changed or it is due to an increase in selling of higher priced products belonging to the specific category.

```{r Pareto analysis}
#################################################
# Select the timeframe of analysis
time.interval <- interval(as.POSIXct("2022-01-01",
                                     format = "%Y-%m-%d",
                                     tz = time_at_tz(Sys.timezone(location = TRUE))),
                          as.POSIXct("2022-12-31",
                                     format = "%Y-%m-%d",
                                     tz = time_at_tz(Sys.timezone(location = TRUE))))

# Select the category: AA, AB, AC, AD, AE
category.filter <- c("AC")

# Select the top N products to check
topN <- 20

#################################################

# Creating the pareto dataset for the plot
pareto.analysis <- df %>% 
  filter(ProductCategory_Lvl2 %in% category.filter) %>% 
  filter(TransactionDate %within% time.interval) %>% 
  select(ProductKey, ProductCategory_Lvl2, ActualSales) %>% 
  group_by(ProductKey, ProductCategory_Lvl2) %>% 
  summarise(tot.revenues = sum(ActualSales)) %>% 
  na.omit() %>% 
  ungroup() %>% 
  arrange(desc(tot.revenues)) %>% 
  mutate(per.revenues = base::cumsum(tot.revenues)/sum(tot.revenues)) 


#Creating the dataset with the top N products
topN.products <- pareto.analysis %>% 
  filter(ProductKey %in% pareto.analysis$ProductKey[1:topN])

# Pareto analysis plot
ggplot(data = topN.products, aes(x = factor(ProductKey, levels = ProductKey), y = per.revenues)) +
  geom_bar(stat = "identity", aes(fill = topN.products$tot.revenues, alpha = 0.6)) +
  geom_hline(yintercept = 0.75, colour = "blue") +
  geom_hline(yintercept = 0.90, colour = "red") +
  geom_point() +
  geom_path() +
  scale_x_discrete(breaks = topN.products$ProductKey) +
  ylab("Cumulated revenues") +
  xlab("ProductKey") + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
        panel.background = element_rect(fill=NA),
        plot.background = element_rect(fill=NA),
        legend.position =  'none',
        axis.title.x = element_blank(),
        axis.title.y = element_blank()) 
# Not visible with many Product Keys
```


# Product deep dive
```{r Deep dive}
################################################
# Select product key to explore
product.code <- 49329

# Select starting date
starting.date <- "2020-01-01"
# Select ending date
ending.date <- "2022-12-31"

################################################

# Select the timeframe of analysis
time.interval <- interval(as.POSIXct(starting.date, # Starting date
                                     format = "%Y-%m-%d",
                                     tz = time_at_tz(Sys.timezone(location = TRUE))),
                          as.POSIXct(ending.date, # Ending date
                                     format = "%Y-%m-%d",
                                     tz = time_at_tz(Sys.timezone(location = TRUE))))

# Preparing the full dataset of transactions
product.deep.dive.df <- df %>% 
  filter(TransactionDate %within% time.interval & 
           ProductKey == as.character(product.code))

# Comparing the sales volumes of the product to those of the category
sales.volumes.product <- product.deep.dive.df %>% 
  group_by(Month = month(TransactionDate), Year = year(TransactionDate)) %>% 
  arrange(Month, Year) %>% 
  summarise(Volumes = sum(UnitVolume),
            ActualSales = sum(ActualSales),
            SalesDiscount = sum(SalesDiscount)) %>% 
  ungroup() %>% 
  mutate(TransactionPeriod = paste(Year, Month, sep = "-")) %>% 
  arrange(Month) %>% 
  arrange(Year) %>% 
  mutate(SalesDeviation = (ActualSales-mean(ActualSales))/sd(ActualSales))

sales.volumes.category <- df %>% 
  filter(TransactionDate %within% time.interval & 
           ProductCategory_Lvl2 == unique(ProductCategory_Lvl2[ProductKey == product.code])) %>% 
  group_by(Month = month(TransactionDate), Year = year(TransactionDate)) %>% 
  arrange(Month, Year) %>% 
  summarise(Volumes = sum(UnitVolume),
            ActualSales = sum(ActualSales),
            SalesDiscount = sum(SalesDiscount)) %>% 
  ungroup() %>% 
  mutate(TransactionPeriod = paste(Year, Month, sep = "-")) %>% 
  arrange(Month) %>% 
  arrange(Year) %>% 
  mutate(SalesDeviation = (ActualSales-mean(ActualSales))/sd(ActualSales))
  
deep.dive.final <- left_join(sales.volumes.product, sales.volumes.category, by = "TransactionPeriod") 


# Plotting sales
ggplot(data = deep.dive.final, aes(x = factor(TransactionPeriod, levels = TransactionPeriod),
                                         y = SalesDeviation.x,
                                         group = 1)) +
  geom_line(aes(y = SalesDeviation.x), colour = "red") +
  geom_line(aes(y = SalesDeviation.y), colour = "blue") +
  geom_point() +
  labs(title = paste("Product code:", as.character(product.code), "Category:",
                      unique(df$ProductCategory_Lvl2[df$ProductKey == product.code]), sep = " "),
       x = "Transaction Period",
       y = "Sales Variation") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=0.5)) 


# Summary statistics: Frequency of distribution channel
print("Transaction frequency:")
table(product.deep.dive.df$DistributionChannel)

```

```{r Brands}
df$BrandKey <- as.factor(df$BrandKey)
print(paste("There are", length(unique(df$BrandKey)), "unique brand keys in the dataset", sep = " "))

brand <- df %>% 
  select(ActualSales, BrandKey) %>%  
  group_by(BrandKey) %>% 
  summarize(BrandImportance = sum(ActualSales))

ggplot(data=brand, aes(x=BrandKey, y=BrandImportance)) +
  geom_bar(stat="identity", fill="steelblue") +
  geom_text(aes(label=round(BrandImportance/sum(BrandImportance),3), vjust=-0.3)) +
  theme_minimal()
  
```
BrandKey 3521 makes almost all the sales (96)


```{r Upstream Bargaining Power?}
df$SupplierKey <- as.factor(df$SupplierKey)
length(unique(df$SupplierKey))

BP <- df %>% 
  group_by(SupplierKey) %>% 
  summarise(Frequency = n(),
            Importance = sum(ActualSales),
            Differentiation = length(unique(ProductKey)))

ggplot(BP, aes(x=Importance, y=Frequency, 
               color=Differentiation, size=Importance)) +
  geom_point() + 
  geom_text(aes(label=SupplierKey, 
            check_overlap = TRUE, 
            vjust = "inward", hjust = "inward")) + 
  theme_minimal() + 
  theme(legend.position = "none")

# Comment: More suppliers are involved in for both a considerable provision in terms of quantity of  goods sold and of value. This should theoretically mean that the company has a good bargaining power. What about those 3 suppliers that provide a number of goods' sold lower than 12? Are their products of low quality? 
```

```{r Sales and Discounts: CHECKAAAA}

SD <- transaction.df %>% 
  group_by(month(TransactionDate), year(TransactionDate)) %>% 
  summarise(Daily_Mean = mean(ActualSales),
                Daily_Sum = sum(ActualSales),
                Daily_Discount = -sum(SalesDiscount),
                Volumes = sum(UnitVolume))

plot(myts <- ts(SD$Daily_Sum, start=c(2020, 1), end=c(2022, 12), frequency=12)) 
plot(decomposition <- stl(myts, s.window = "periodic"))

hW <- HoltWinters(myts)
cor(decomposition$time.series[,3], SD$Daily_Discount)

plot(mytsDi <- ts(SD$Daily_Discount, start=c(2020, 1), end=c(2022, 12), frequency=12)) 
plot(decompositionD <- stl(mytsDi, s.window = "periodic"))

comparison <- as.data.frame(cbind(decomposition$time.series[,1],decompositionD$time.series[,1], seq(1,length(decomposition$time.series[,1]),1)))
colnames(comparison) <- c("S", "D", "T")

cpi <- cpi.df %>% 
  filter(year(Date_daily) > 2019) %>% 
  group_by(M = month(Date_daily), Y = year(Date_daily)) %>% 
  summarise(Month = mean(CPI_Monthly)) %>% 
  arrange(Y,M)

myCPI <- ts(cpi$Month, start=c(2020, 1), end=c(2022, 12), frequency=12)
plot(decoCPI <- stl(myCPI, s.window = "periodic"))


ggplot(comparison, aes(x = T, y = scale(S))) +
  geom_line() +
  geom_line(aes(y = scale(D), colour = "blue")) 

SD$ChangeInDiscount <- c(diff(SD$Daily_Discount),0)
SD$ChangeInSales<- c(diff(SD$Daily_Sum), 0)

colnames(SD)[1] <- "TransactionDate" 


ggplot(SD, aes(x = TransactionDate, y = Daily_Sum)) +
            geom_line(color = "deepskyblue4") + 
            geom_col(aes(x = TransactionDate, 
                         y = Daily_Discount*(min(Daily_Sum)/max(Daily_Discount)))) +
            scale_y_continuous(
            # Features of the first axis
            name = "AggregateSales",
            # Add a second axis and specify its features
            sec.axis = sec_axis(~.*min(SD$Daily_Sum)/max(SD$Daily_Discount), 
            name="AggregateDiscount")) +
            theme(# panel.grid.major = element_blank(),
                  # axis.line = element_line(colour = "black"),
                  axis.title.x = element_blank(),
                  axis.title.y = element_blank(),
                  panel.background = element_rect(fill=NA),
                  plot.background = element_rect(fill=NA))

```
```{r Correlation(Change in Discounts and Sales)}
# Comparison with Changes in Volumes and Discounts
ggplot(SD, aes(x = TransactionDate, y = ChangeInSales)) +
            geom_line(color = "deepskyblue4") + 
            geom_col(aes(x = TransactionDate, 
                         y = ChangeInDiscount)) +
            theme(# panel.grid.major = element_blank(),
                  # axis.line = element_line(colour = "black"),
                  axis.title.x = element_blank(),
                  axis.title.y = element_blank(),
                  panel.background = element_rect(fill=NA),
                  plot.background = element_rect(fill=NA))

cor(SD$ChangeInDiscount, SD$ChangeInSales)

ggplot(SD, aes(x=ChangeInDiscount, y=ChangeInSales)) +
  geom_point() + 
  theme_minimal() + 
  theme(legend.position = "none") + 
  geom_smooth(method=lm,  linetype="dashed",
             color="darkblue", fill="lightblue")

summary(lm1 <- lm(ChangeInSales ~ ChangeInDiscount, data = SD))
plot(rstandard(lm1))

```

```{r Is Inflation Relevant?}
# De-trending Sales

DTS <- transaction.df %>% 
  group_by(TransactionDate, WeekendFlag, Festivity, CPI_daily) %>% 
  summarise(Sales = sum(ActualSales),
            Discounts = sum(SalesDiscount)) %>% 
  mutate(DeflatedSales = Sales/CPI_daily) %>% 
  mutate(FestivityFlag = case_when(is.na(Festivity) ~ 0,
                                   TRUE ~ 1))

DTS$Trend <- seq(1,length(DTS$TransactionDate), 1)

# Is there a trend?
summary(lm <- lm(Sales ~ Trend, data = DTS))
# Cool Plot Missing...

summary(lmD <- lm(DeflatedSales ~ Trend, data = DTS)) # Slight smaller t-value w.r.t trend but always extremely significant...What does this means? That CPI explains slightly the trend but it is definetely what drives the upwards patter .



```


```{r Exploring sales and discount for single product}
################################################
# Select product key to explore
product.code <- c(49333, 49341)

# Select starting date
starting.date <- "2021-01-01"
# Select ending date
ending.date <- "2022-12-31"

################################################

# Select the timeframe of analysis
time.interval <- interval(as.POSIXct(starting.date, # Starting date
                                     format = "%Y-%m-%d",
                                     tz = time_at_tz(Sys.timezone(location = TRUE))),
                          as.POSIXct(ending.date, # Ending date
                                     format = "%Y-%m-%d",
                                     tz = time_at_tz(Sys.timezone(location = TRUE))))

# Preparing the full dataset of transactions
product.sales.discounts <- transaction.df %>% 
  filter(TransactionDate %within% time.interval & 
           ProductKey %in% as.character(product.code)) %>% 
  group_by(Year = year(TransactionDate), Week = week(TransactionDate)) %>% 
  summarise(ActualSales = sum(ActualSales), 
            TotalDiscounts = sum(SalesDiscount)) %>% 
  arrange(Week) %>% 
  arrange(Year) %>% 
  mutate(Period = paste(Year, Week, sep = "-")) %>% 
  ungroup()

product.sales <- product.sales.discounts %>% 
  select(Value = ActualSales, Period, Week, Year) %>% 
  mutate(flag = replicate(nrow(product.sales.discounts),"ActualSales"))
  

product.discounts <- product.sales.discounts %>% 
  select(Value = TotalDiscounts, Period, Week, Year) %>% 
  mutate(flag = replicate(nrow(product.sales.discounts),"Discounts"))

product.sales.discounts.final = rbind(product.sales, product.discounts)

product.sales.discounts.final <- product.sales.discounts.final %>% 
  group_by(Year, Week) %>% 
  arrange(Week) %>% 
  arrange(Year)

product.sales.discounts.final$Value[product.sales.discounts.final$flag == "Discounts"] <- -product.sales.discounts.final$Value[product.sales.discounts.final$flag == "Discounts"]

product.sales.discounts.final$Value <- round(product.sales.discounts.final$Value, digits = 0)


ggplot(product.sales.discounts.final, aes(fill=flag,
                                          y=Value,
                                          x=factor(Period, levels = unique(Period)))) + 
  geom_bar(position="stack", stat="identity") + 
  scale_fill_viridis(discrete=TRUE, name="") +
  ylab("Sales Value") + 
  xlab("Year - Week") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=0.5))


```

